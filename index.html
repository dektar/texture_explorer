<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=640, initial-scale=1.0">
    <title>WebGL Demo</title>
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/gl-matrix/2.8.1/gl-matrix-min.js"
      integrity="sha512-zhHQR0/H5SEBL3Wn6yYSaTTZej12z0hVZKOv3TwCUXT1z5qeqGcXJLLrbERYRScEDDpYIJhPC1fk31gqR783iQ=="
      crossorigin="anonymous"
      defer></script>
      <script src="./webgl.js" type="module"></script>
      <link rel="stylesheet" type="text/css" href="style.css">
  </head>
  <body>
    <h1>Texture mapping explorer</h1>
    <p>Katie Dektar / CS248A final project 2024</p>
    <p>Interactively visualize how a 2D texture map can be wrapped over geometry and projected into screen space.</p>
    <h2>Warp speed</h2>
    <p>
      Below are two images. The first is is a 3D rendering of a textured model, and
      the second is a 2D visualization of texture space. You can see how the texture is warped
      in the first compared to the second during the transformations that take it from object space
      to screen space.
    </p>
    <canvas id="glcanvas" width="640" height="480" alt="3D rendering of an object covered with the texture from the 2D image."></canvas>
    <canvas id="texturecanvas" width="512" height="512" alt="2D image which is used to texture the 3D object."></canvas>
    <br/>
    <fieldset>
      <legend>Object</legend>
      <label for="modelType">Model type</label>
      <select id="modelType" name="modelType">
        <option value="square">Square</option>
        <option value="cube">Cube</option>
      </select>
      <br/>
      <label for="rotation">Rotation</label>
      <input type="range" min="0" max="359" value="30" id="rotation"/>
      <br/>
      <label for="scale">Object scale</label>
      <input type="range" min="20" max="200" value="100" id="scale"/>
    </fieldset>
    <fieldset>
      <legend>Texture mapping</legend>
      <input type="checkbox" value="nearest neighbor" id="nearestNeighbor" checked/>
      <label for="nearestNeighbor">Nearest neighbor</label>
    </fieldset>
    <fieldset>
      <legend>Reset texture</legend>
      <label for="baseTextureType">Base</label>
      <select name="baseTextureType" id="baseTextureType">
        <option value="gradient">Gradient</option>
        <option value="grid">Simple grid</option>
        <option value="uv_grid">UV grid</option>
        <option value="grey">Grey</option>
        <option value="cat">Cat</option>
      </select>
      <br/>
      <input type="button" value="Reset" id="clear"></input>
    </fieldset>
    <h2>Draw your own!</h2>
    <p>
      Click or tap and drag to draw on the 2D or 3D model see your drawings reflected into both the 
      texture and the textured geometry. Note how different your drawings look in 2D or 3D! If you
      draw a recognizable shape on one side it may get all warped on the other side.
      <span class="challenge"><b>Challenge</b>: Can you draw a shape on the flat texture (second image)
        that looks square on the 3D plane (first)?</span> Note, to start over, <i>clear</i> your drawing
        with the controls above.
    </p>
    <p></p>
    <p>
      Use the controls to modify position, size, or type of object, the texture mapping
      interpolation method, or to reset the texture map to different defaults.
      <span class="challenge"><b>Challenge</b>: Change the model to the cube. Can you figure out which
        parts of the texture are mapped to which cube face?</span>
    </p>
  <h2>How does the demo work?</h2>
  <p>
    The demo uses 
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API" about="blank">WebGL</a>
    to create the 3D graphics, and an HTML5 Canvas element to create the texture. Much of the WebGL
    code is quite similar or verbatim from the 
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API/Tutorial" about="blank">
      Mozilla WebGL tutorial</a>.
  </p>
  <h3>Ray tracing</h3>
  <p>
    The most interesting part of the demo is mapping from 3D object space into 2D texture space
    when the pointer is detected over the WebGL canvas element. This requires ray tracing a single
    ray from the camera point through the perspective projection and into object space, then
    intersecting it with the geometry, and finally interpolating the intersection point and the
    (u,v) coordinates of the vertices to get the coordinates in texture space. In more detail,
    this entails:
  </p>
  <ol>
    <li>Convert the pointer point from Canvas coordinates in (0, 0) to (640, 480) to screen coordinates with (x, y) from (-1, -1) (1, 1), and with z = 1.</li>
    <li>Create an unprojectMatrix which is (projectionMatrix * modelViewMatrix)<sup>-1</sup> </li>
    <li>Get objectPoint = unprojectMatrix * screenPoint, representing the pointer in 3D in object coordinates</li>
    <li>Create a camera point at (0, 0, 0), and find the cameraPoint in object coordinates, modelViewMatrix<sup>-1</sup>  * cameraPoint</li>
    <li>Create a ray with origin o at the cameraPoint and direction d = objectPoint - cameraPoint.</li>
    <li>For each triangle:</li>
    <ol>
      <li>Look up the vertices from the triangle indices</li>
      <li>Create the matrix M = [p<sub>1</sub> - p<sub>0</sub>, p<sub>2</sub> - p<sub>0</sub>, -d]</li>
      <li>Solve for [u, v, t] = M<sup>-1</sup>(o - p<sub>0</sub>)</li>
      <li>If t < any previous t, use (u, v) of the triangle to find the (u, v) texture coordinates by interpolating the texture coordinates of the vertices.</li>
    </ol>
    <li>Use the (u, v) from the smallest t, scaled by the texture image (width, height), to figure out where to draw on the texture.</li>
  </ol>
  <h2>Feedback or suggestions?</h2>
  <p>
    The code is open-source at 
    <a href="https://github.com/dektar/texture_explorer" about="blank">
      github.com/dektar/texture_explorer</a>.
    <a href="https://github.com/dektar/texture_explorer/issues/new" about="blank">
      File an issue</a> on GitHub or send a pull request.</p>
  <br/>
  <p>2024, Katie Dektar</p>
  </body>
</html>